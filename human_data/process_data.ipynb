{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 100)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "glove_file = datapath('/Users/haldenl/nlpcapstone/glove/glove.6B.100d.txt')\n",
    "tmp_file = get_tmpfile('test_word2vec.txt')\n",
    "\n",
    "glove2word2vec(glove_file, tmp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeyedVectors.load_word2vec_format(tmp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data to process\n",
    "import json\n",
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "with open('/Users/haldenl/nlpcapstone/data/human_attn_vis_data.json', 'r') as data:\n",
    "    d = json.load(data)\n",
    "    \n",
    "    for k, example in enumerate(d):\n",
    "        input_list = example['article_lst']\n",
    "        output_list = example['decoded_lst']\n",
    "\n",
    "        cross_prod = []\n",
    "\n",
    "        for i, output_token in enumerate(output_list):\n",
    "            for j, input_token in enumerate(input_list):\n",
    "                \n",
    "                weight = 0\n",
    "                if (input_token in model.vocab and output_token in model.vocab):\n",
    "                    weight = model.similarity(input_token, output_token)\n",
    "                \n",
    "                record = {\n",
    "                    'outputIndex': i,\n",
    "                    'outputToken': output_token,\n",
    "                    'inputIndex': j,\n",
    "                    'inputToken': input_token,\n",
    "                    'weight': weight\n",
    "                }\n",
    "\n",
    "                cross_prod.append(record)\n",
    "\n",
    "        with open('/Users/haldenl/nlpcapstone/human_data/human_similarity_data_{0}.json'.format(k), 'w') as out:\n",
    "            json.dump(cross_prod, out, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
