{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'attn_vis_data.json'\n",
    "out_prefix = 'find'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Token:\n",
    "    def __init__(self, text, pos):\n",
    "        self.text = text\n",
    "        self.pos = pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "def getTagged(tokens):\n",
    "    tagged = nltk.pos_tag(tokens)\n",
    "    result = [Token(x[0], x[1]) for x in tagged]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('/Users/haldenl/nlpcapstone/data/{0}'.format(data_path), 'r') as data:\n",
    "    d = json.load(data)\n",
    "\n",
    "    for k, example in enumerate(d):\n",
    "        attn_dist = example['attn_dists']\n",
    "        input_list = getTagged(example['article_lst'])\n",
    "        output_list = getTagged(example['decoded_lst'])\n",
    "        \n",
    "        attentionRecords = []\n",
    "        inputRecords = []\n",
    "        outputRecords = []\n",
    "        \n",
    "        for i, output_token in enumerate(output_list):\n",
    "            for j, input_token in enumerate(input_list):\n",
    "                if (j >= len(attn_dist[i])):\n",
    "                    attentionRecords.append({\n",
    "                        'inputIndex': j,\n",
    "                        'outputIndex': i,\n",
    "                        'weight': 0\n",
    "                    })\n",
    "                \n",
    "                else: \n",
    "                    attn_weight = attn_dist[i][j]\n",
    "\n",
    "                    attentionRecords.append({\n",
    "                        'inputIndex': j,\n",
    "                        'outputIndex': i,\n",
    "                        'weight': attn_weight\n",
    "                    })\n",
    "                \n",
    "        for i, input_token in enumerate(input_list):\n",
    "            inputRecords.append({\n",
    "                'index': i,\n",
    "                'token': input_token.text,\n",
    "                'pos': input_token.pos\n",
    "            })\n",
    "            \n",
    "        for i, output_token in enumerate(output_list):\n",
    "            outputRecords.append({\n",
    "                'index': i,\n",
    "                'token': output_token.text,\n",
    "                'pos': output_token.pos\n",
    "            })\n",
    "            \n",
    "        output = {\n",
    "            'attentionRecords': attentionRecords,\n",
    "            'inputTokens': inputRecords,\n",
    "            'outputTokens': outputRecords\n",
    "        }\n",
    "\n",
    "        with open('/Users/haldenl/nlpcapstone/data/{0}_data_{1}.json'.format(out_prefix, k), 'w') as out:\n",
    "            json.dump(output, out, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
