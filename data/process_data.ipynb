{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'attn_vis_data.json'\n",
    "out_prefix = 'machine'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Token:\n",
    "    def __init__(self, text, pos):\n",
    "        self.text = text\n",
    "        self.pos = pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "def getTagged(tokens):\n",
    "    tagged = nltk.pos_tag(tokens)\n",
    "    result = [Token(x[0], x[1]) for x in tagged]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('/Users/haldenl/nlpcapstone/data/{0}'.format(data_path), 'r') as data:\n",
    "    d = json.load(data)\n",
    "\n",
    "    for k, example in enumerate(d):\n",
    "        attn_dist = example['attn_dists']\n",
    "        input_list = getTagged(example['article_lst'])\n",
    "        output_list = getTagged(example['decoded_lst'])\n",
    "        \n",
    "        cross_prod = []\n",
    "        \n",
    "        for i, output_token in enumerate(output_list):\n",
    "            for j, input_token in enumerate(input_list):\n",
    "                if (j >= len(attn_dist[i])):\n",
    "                    break\n",
    "                \n",
    "                attn_weight = attn_dist[i][j]\n",
    "                                \n",
    "                record = {\n",
    "                    'outputIndex': i,\n",
    "                    'outputToken': output_token.text,\n",
    "                    'outputPos': output_token.pos,\n",
    "                    'inputIndex': j,\n",
    "                    'inputToken': input_token.text,\n",
    "                    'inputPos': input_token.pos,\n",
    "                    'weight': attn_weight\n",
    "                }\n",
    "\n",
    "                cross_prod.append(record)\n",
    "\n",
    "        with open('/Users/haldenl/nlpcapstone/data/{0}_data_{1}.json'.format(out_prefix, k), 'w') as out:\n",
    "            json.dump(cross_prod, out, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
