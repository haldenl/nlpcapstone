{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'attn_vis_data.json'\n",
    "out_prefix = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Token:\n",
    "    def __init__(self, text, pos):\n",
    "        self.text = text\n",
    "        self.pos = pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "def getTagged(tokens):\n",
    "    tagged = nltk.pos_tag(tokens)\n",
    "    result = [Token(x[0], x[1]) for x in tagged]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DT', 'JJ', 'NN', 'WP', 'VBD', 'TO', 'CD', 'NN', 'IN', 'VBG', 'DT', 'NN', 'IN', 'NN', 'DT', 'NN', 'VBZ', 'RB', 'VBG', 'PRP$', 'JJ', ':', 'CC', 'RB', 'VBG', 'PDT', 'DT', 'NN', 'PRP', 'VBD', 'TO', 'VB', '.', 'VB', 'NN', ',', 'CD', ',', 'VBN', 'IN', 'VBG', 'PRP$', 'NN', 'IN', 'NN', ',', 'NNP', 'CC', 'NNS', 'IN', 'NN', 'DT', 'NN', '.', 'PRP$', 'NN', 'VBN', 'TO', 'VB', 'VBN', 'IN', 'IN', 'JJ', 'NN', 'IN', 'NN', 'IN', 'NN', ',', 'NNS', 'CC', 'NN', 'IN', 'NN', 'CC', 'NN', 'CC', 'NNS', 'CC', 'NNS', 'IN', 'NN', '.', 'NN', 'NN', 'VBZ', 'VBN', 'NN', 'IN', 'PRP$', 'NN', 'NN', 'IN', 'VBG', 'PRP$', 'JJ', 'NN', 'WDT', 'VBD', 'PRP', 'VB', 'DT', 'NN', 'DT', 'NN', ',', 'PRP', 'VBZ', 'RB', 'VBN', 'IN', 'DT', 'NNS', 'NN', 'CD', 'NN', 'VBD', 'NNP', 'TO', 'DT', 'NN', 'CD', 'NN', 'RB', 'NNP', '.', 'IN', 'VBG', 'JJ', 'JJ', 'NN', 'VBD', 'DT', 'NN', 'CD', ',', 'RB', 'PRP', 'RB', 'VBZ', 'RP', 'DT', 'NN', 'IN', 'PRP$', 'JJ', 'NNS', '.', 'CC', 'PRP', 'VBD', 'RP', 'DT', 'NN', 'CC', 'VBD', 'DT', 'NN', 'IN', 'NN', 'IN', 'NN', 'CC', 'NN', 'CC', 'NN', ',', 'JJ', 'NN', 'IN', 'NN', 'CC', 'JJ', 'NNS', 'IN', 'PRP$', 'JJ', 'NNS', '.', 'NN', ',', 'IN', 'JJ', 'NNS', ',', 'RB', ',', 'VBZ', 'PRP', 'VBZ', 'IN', 'DT', 'JJ', 'NN', 'IN', 'VBG', 'CD', 'NN', 'CC', 'VBG', 'IN', 'NN', 'NN', 'CD', 'TO', 'NN', 'CD', '.', 'PRP', 'VBZ', 'VBN', 'VBN', 'VBG', 'NN', 'POS', 'JJS', 'NN', 'IN', 'DT', 'NN', 'JJ', 'NN', 'IN', 'JJ', 'NNS', '.', 'PRP', 'VBD', ':', \"''\", 'JJ', 'VBP', 'IN', 'DT', 'JJ', 'NN', 'IN', 'VBG', 'NN', '.', 'IN', 'NN', ',', 'JJ', 'VBP', 'RB', 'JJ', 'IN', 'NNS', 'WP', 'VBP', 'VBP', 'VBN', 'IN', 'DT', 'NN', 'RB', 'MD', 'RB', 'VB', 'NN', 'VBP', 'DT', 'JJ', 'NN', '.', '``', 'IN', 'PRP', 'IN', 'PRP', 'VBZ', 'DT', 'NN', 'IN', 'DT', 'NN', 'WDT', 'VBZ', 'VBN', 'DT', 'JJS', ':', 'NN', 'VBP', 'NN', ',', 'JJR', 'CC', 'RB', 'RBR', 'JJ', 'RB', '.', 'NN', ',', 'VBD', 'IN', 'PRP$', 'NN', 'NN', ',', 'VBD', 'DT', 'VBG', 'NN', 'IN', 'CD', 'IN', 'DT', 'NN', 'TO', 'VB', 'DT', 'NN', ',', 'PRP', 'VBZ', 'PRP', 'VBD', 'VBN', 'IN', 'JJ', 'NN', 'NN', ',', 'RB', 'NN', 'CC', 'IN', 'PRP', 'VBD', 'JJ', 'RB', '.', 'NN', 'VBD', 'RB', 'JJ', 'IN', 'DT', 'NN', 'CC', 'VBD', 'IN', 'DT', 'NNS', 'NNS', 'TO', 'PRP$', 'NN', 'IN', 'JJ', 'CC', 'NNS', 'CC', 'NNP', '.', 'RB', 'DT', 'NN', 'CD', ',', 'VBZ', 'RB', 'JJR', 'VBZ', 'DT', 'NN', 'TO', 'VB', 'DT', 'JJ', 'NN', 'IN', 'JJ', 'DT', 'NN', '.', 'PRP', 'VBD', ':', \"''\", 'NNS', 'RB', 'VBP', 'DT', 'PRP$', 'JJ', 'NNS', 'IN', 'NNS', 'CC', 'NNS', 'CC', 'NN', 'NNS', 'CC', 'JJ', 'VBP', 'VBN', 'WRB', 'TO', 'VB', 'JJ', 'NNS', 'IN', 'VBG', 'JJ', 'NN', 'CC', 'VBG', 'IN', 'JJ', 'NNS', 'NN', 'RB', 'IN', 'NN', 'CC', 'NN', '.', '``', 'PRP', 'VBZ', 'IN', 'RB', 'RB', 'IN', 'DT', 'NN', 'IN', 'PRP$', 'NN', 'CC', 'PRP', 'MD', 'DT', 'VB', 'DT', 'JJ', 'NNS', '.', \"''\", 'NN', 'VBD', 'RB', 'CD', 'WRB', 'PRP', 'VBD', 'DT', 'NN', 'IN', 'NN', 'CD', 'CC', 'VBZ', 'IN', 'VBN', 'TO', 'CD', 'CD', '.', 'PRP', 'VBD', ':', '``', 'IN', 'NN', 'VBD', 'DT', 'NN', 'NN', 'VBP', 'IN', 'DT', 'JJ', 'NN', 'NN', '.', 'JJ', 'MD', 'VB', 'PRP', 'VBD', 'RB', 'VB', 'PRP', 'IN', 'NN', 'VBD', 'JJR', 'IN', 'JJS', 'JJ', 'NNS', ',', 'CC', 'DT', 'VBD', 'RB', 'IN', 'DT', 'NN', '.', \"''\", 'NN', 'VBD', 'NN', 'IN', 'NNS', 'CC', 'VBD', 'RB', 'VBG', 'RP', 'NNS', 'CC', 'VBG', 'JJ', 'JJ', 'NNS', 'MD', 'VB', 'PRP', 'JJ', 'CC', 'IN', 'IN', 'NN', '.', \"''\", 'NN', 'POS', 'NN', 'VBD', 'RB', 'VBG', 'DT', 'JJ', 'NN', 'IN', 'PRP$', 'NN', 'CC', 'PRP', 'VBD', 'IN', 'JJ', 'NN', 'NN', ',', 'JJ', 'RB', 'NN', 'CC', 'VBD', 'JJ', 'RB', '.']\n",
      "output index 0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'Token' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-acfcb5d036ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0mattn_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_dist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0minput_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetTokenWithInfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m                 \u001b[0moutput_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetTokenWithInfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-6bb291b8bada>\u001b[0m in \u001b[0;36mgetTokenWithInfo\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgetTokenWithInfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/language.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, disable)\u001b[0m\n\u001b[1;32m    341\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0;34m'An'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'NN'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \"\"\"\n\u001b[0;32m--> 343\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m             raise ValueError(Errors.E088.format(length=len(text),\n\u001b[1;32m    345\u001b[0m                                                 max_length=self.max_length))\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'Token' has no len()"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('/Users/haldenl/nlpcapstone/data/{0}'.format(data_path), 'r') as data:\n",
    "    d = json.load(data)\n",
    "\n",
    "    for k, example in enumerate(d):\n",
    "        attn_dist = example['attn_dists']\n",
    "        input_list = getTagged(example['article_lst'])\n",
    "        output_list = getTagged(example['decoded_lst'])\n",
    "        \n",
    "        cross_prod = []\n",
    "        \n",
    "        for i, output_string in enumerate(output_list):\n",
    "            print('output index ' + str(i))\n",
    "            for j, input_string in enumerate(input_list):\n",
    "                if (j >= len(attn_dist[i])):\n",
    "                    break\n",
    "                \n",
    "                attn_weight = attn_dist[i][j]\n",
    "                \n",
    "                input_token = getTokenWithInfo(input_string)\n",
    "                output_token = getTokenWithInfo(output_string)\n",
    "                \n",
    "                record = {\n",
    "                    'outputIndex': i,\n",
    "                    'outputToken': output_string,\n",
    "                    'outputPos': output_token.pos_,\n",
    "                    'inputIndex': j,\n",
    "                    'inputToken': input_string,\n",
    "                    'inputPos': input_token.pos_,\n",
    "                    'weight': attn_weight\n",
    "                }\n",
    "\n",
    "                cross_prod.append(record)\n",
    "\n",
    "        with open('/Users/haldenl/nlpcapstone/data/{0}_data_{1}.json'.format(out_prefix, k), 'w') as out:\n",
    "            json.dump(cross_prod, out, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
